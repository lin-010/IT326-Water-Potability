{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccf6f9a1",
   "metadata": {},
   "source": [
    "# Phase 3 – Integrated Data Mining Notebook  \n",
    "## Water Potability Prediction (IT326) /  توقّع صلاحية مياه الشرب\n",
    "\n",
    "This notebook presents the complete data mining pipeline required for the project:\n",
    "\n",
    "1. **Phase 1 – Exploratory Data Analysis (EDA)**  \n",
    "2. **Phase 2 – Data Preprocessing**  \n",
    "3. **Phase 3 – Classification (Decision Trees) and Clustering (K-means)**  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6908ba20",
   "metadata": {},
   "source": [
    "## 1. Environment Setup / إعداد بيئة العمل"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abb84f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 5)\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c7bd90",
   "metadata": {},
   "source": [
    "## 2. Problem & Data Overview / وصف المشكلة والبيانات (Phase 1)\n",
    "\n",
    "- **Problem:** Predict whether a water sample is potable (safe to drink) based on its chemical attributes.  \n",
    "- **Dataset:** Water Potability dataset (Kaggle).  \n",
    "- **Target attribute:** `Potability` (0 = not potable, 1 = potable).  \n",
    "\n",
    "> الهدف: بناء نماذج تنقيب بيانات لتوقّع صلاحية الماء للشرب، بالإضافة إلى اكتشاف مجموعات طبيعية (Clusters) داخل البيانات.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0059efc",
   "metadata": {},
   "source": [
    "### 2.1 Load Raw Dataset / قراءة البيانات الخام"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c64316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load RAW dataset from GitHub\n",
    "# Update the URL if the path or file name changes in the repository.\n",
    "\n",
    "url_raw = \"https://raw.githubusercontent.com/lin-010/IT326-Water-Potability/refs/heads/main/Dataset/Raw_dataset.csv\"\n",
    "df_raw = pd.read_csv(url_raw)\n",
    "\n",
    "print(\"Raw dataset shape:\", df_raw.shape)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d2df9d",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA) / تحليل استكشافي (Phase 1)\n",
    "\n",
    "Quick inspection of:\n",
    "\n",
    "- Data types  \n",
    "- Summary statistics  \n",
    "- Class distribution  \n",
    "- Missing values  \n",
    "\n",
    "> في هذا الجزء نكوّن صورة عامة عن البيانات قبل البدء في المعالجة والبناء النماذج.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5df0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset info\n",
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56bc264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "df_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15361ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution for Potability\n",
    "if \"Potability\" in df_raw.columns:\n",
    "    print(\"Class distribution (Potability):\")\n",
    "    print(df_raw[\"Potability\"].value_counts())\n",
    "else:\n",
    "    print(\"Warning: 'Potability' column not found – check dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321eac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values per column\n",
    "df_raw.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b99261",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing / معالجة البيانات (Phase 2)\n",
    "\n",
    "The preprocessing pipeline used in this notebook:\n",
    "\n",
    "1. Work on a copy of the raw dataset.  \n",
    "2. Handle missing numeric values using **median imputation**.  \n",
    "3. Keep the numeric scale as-is for Decision Trees (no scaling required).  \n",
    "4. Later, apply **StandardScaler** separately for K-means (distance-based).  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6bd645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start preprocessing from the raw dataset\n",
    "df = df_raw.copy()\n",
    "\n",
    "# Median imputation for numeric columns\n",
    "numeric_cols = df.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "for col in numeric_cols:\n",
    "    median_value = df[col].median()\n",
    "    df[col].fillna(median_value, inplace=True)\n",
    "\n",
    "# Check missing values after imputation\n",
    "print(\"Missing values after median imputation:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\nPreprocessed dataset shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d89780",
   "metadata": {},
   "source": [
    "### 4.1 Features and Target / فصل المتغيرات عن المخرج\n",
    "\n",
    "- `X` = input features (attributes)  \n",
    "- `y` = target class label (`Potability`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477f84a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (X) and target (y)\n",
    "\n",
    "target_column = \"Potability\"\n",
    "\n",
    "if target_column not in df.columns:\n",
    "    raise ValueError(f\"Target column '{target_column}' not found in dataframe.\")\n",
    "\n",
    "X = df.drop(target_column, axis=1)\n",
    "y = df[target_column]\n",
    "\n",
    "print(\"Shape of features (X):\", X.shape)\n",
    "print(\"Shape of target (y):\", y.shape)\n",
    "print(\"\\nClass distribution:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c21180",
   "metadata": {},
   "source": [
    "## 5. Decision Tree Classification / التصنيف باستخدام شجرة القرار (Phase 3)\n",
    "\n",
    "We build Decision Tree models using:\n",
    "\n",
    "- **Criteria:** `gini` and `entropy`  \n",
    "- **Train/Test splits:** 90/10, 80/20, 70/30  \n",
    "\n",
    "For each configuration we compute:\n",
    "\n",
    "- Accuracy on the test set  \n",
    "- Confusion matrix  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4beb49d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to train and evaluate a Decision Tree\n",
    "\n",
    "def run_decision_tree(X, y, train_size, criterion, random_state=42):\n",
    "    \"\"\"Train a DecisionTreeClassifier and return model, accuracy, confusion matrix, and data splits.\"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y,\n",
    "        train_size=train_size,\n",
    "        random_state=random_state,\n",
    "        stratify=y\n",
    "    )\n",
    "\n",
    "    clf = DecisionTreeClassifier(criterion=criterion, random_state=random_state)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    return clf, acc, cm, (X_train, X_test, y_train, y_test, y_pred)\n",
    "\n",
    "\n",
    "train_sizes = [0.9, 0.8, 0.7]\n",
    "criteria = [\"gini\", \"entropy\"]\n",
    "\n",
    "results_clf = []       # summary table\n",
    "models_clf = {}        # store models and confusion matrices\n",
    "\n",
    "for crit in criteria:\n",
    "    for ts in train_sizes:\n",
    "        clf, acc, cm, data_split = run_decision_tree(X, y, train_size=ts, criterion=crit)\n",
    "\n",
    "        results_clf.append({\n",
    "            \"criterion\": crit,\n",
    "            \"train_size\": ts,\n",
    "            \"test_size\": round(1 - ts, 2),\n",
    "            \"accuracy\": acc\n",
    "        })\n",
    "\n",
    "        key = f\"{crit}_train{int(ts * 100)}\"\n",
    "        models_clf[key] = {\n",
    "            \"model\": clf,\n",
    "            \"confusion_matrix\": cm,\n",
    "            \"data_split\": data_split\n",
    "        }\n",
    "\n",
    "results_clf_df = pd.DataFrame(results_clf)\n",
    "results_clf_df.sort_values(by=[\"train_size\", \"criterion\"], ascending=[False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479612b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices for all Decision Tree configurations\n",
    "\n",
    "for key, info in models_clf.items():\n",
    "    cm = info[\"confusion_matrix\"]\n",
    "    _, X_test, _, y_test, y_pred = info[\"data_split\"]\n",
    "\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "    disp.plot(values_format='d')\n",
    "    plt.title(f\"Confusion Matrix - {key.replace('_', ', ')}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce223dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model (highest accuracy) and tree visualization\n",
    "\n",
    "best_idx = results_clf_df[\"accuracy\"].idxmax()\n",
    "best_row = results_clf_df.loc[best_idx]\n",
    "best_key = f\"{best_row['criterion']}_train{int(best_row['train_size'] * 100)}\"\n",
    "\n",
    "print(\"Best model settings:\")\n",
    "print(best_row)\n",
    "\n",
    "best_model = models_clf[best_key][\"model\"]\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plot_tree(\n",
    "    best_model,\n",
    "    feature_names=X.columns,\n",
    "    class_names=[\"Not potable (0)\", \"Potable (1)\"],\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    fontsize=8\n",
    ")\n",
    "plt.title(f\"Decision Tree - Best model ({best_key})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a25692",
   "metadata": {},
   "source": [
    "## 6. K-means Clustering / التجميع باستخدام K-means (Phase 3)\n",
    "\n",
    "We apply K-means clustering on the feature space (without the label):\n",
    "\n",
    "1. Drop `Potability` from the feature set.  \n",
    "2. Standardize features using `StandardScaler`.  \n",
    "3. Try K ∈ {2, 3, 4, 5}.  \n",
    "4. For each K, compute:\n",
    "   - Total within-cluster sum of squares (**inertia**)  \n",
    "   - Average **silhouette score**  \n",
    "5. Use Elbow and Silhouette plots to choose the most suitable K.  \n",
    "\n",
    "> هذه الخطوة مطلوبة حسب تعليمات المشروع لاستخدام K-means في الـ clustering وتحليل المجموعات الناتجة.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a5e3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature space for K-means (without target)\n",
    "\n",
    "X_features = df.drop(target_column, axis=1)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_features)\n",
    "\n",
    "# K-means for different K values\n",
    "k_values = [2, 3, 4, 5]\n",
    "\n",
    "kmeans_results = []\n",
    "cluster_labels_dict = {}\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "    inertia = kmeans.inertia_\n",
    "    sil_score = silhouette_score(X_scaled, labels)\n",
    "\n",
    "    kmeans_results.append({\n",
    "        \"K\": k,\n",
    "        \"inertia\": inertia,\n",
    "        \"silhouette\": sil_score\n",
    "    })\n",
    "\n",
    "    cluster_labels_dict[k] = {\n",
    "        \"model\": kmeans,\n",
    "        \"labels\": labels\n",
    "    }\n",
    "\n",
    "kmeans_results_df = pd.DataFrame(kmeans_results)\n",
    "kmeans_results_df.sort_values(\"K\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b904c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow plot (K vs inertia)\n",
    "\n",
    "plt.plot(kmeans_results_df[\"K\"], kmeans_results_df[\"inertia\"], marker=\"o\")\n",
    "plt.xlabel(\"Number of clusters (K)\")\n",
    "plt.ylabel(\"Total within-cluster sum of squares (Inertia)\")\n",
    "plt.title(\"Elbow Method for K-means\")\n",
    "plt.xticks(k_values)\n",
    "plt.show()\n",
    "\n",
    "# Silhouette plot (K vs silhouette)\n",
    "\n",
    "plt.plot(kmeans_results_df[\"K\"], kmeans_results_df[\"silhouette\"], marker=\"o\")\n",
    "plt.xlabel(\"Number of clusters (K)\")\n",
    "plt.ylabel(\"Average Silhouette Coefficient\")\n",
    "plt.title(\"Silhouette Scores for Different K\")\n",
    "plt.xticks(k_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfddff55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best K based on silhouette score and PCA visualization\n",
    "\n",
    "best_k_idx = kmeans_results_df[\"silhouette\"].idxmax()\n",
    "best_k = int(kmeans_results_df.loc[best_k_idx, \"K\"])\n",
    "print(\"Best K based on silhouette:\", best_k)\n",
    "\n",
    "best_labels = cluster_labels_dict[best_k][\"labels\"]\n",
    "\n",
    "# PCA to 2D\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=best_labels, alpha=0.6)\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "plt.title(f\"K-means Clusters (K = {best_k}) in PCA space\")\n",
    "plt.show()\n",
    "\n",
    "# Attach cluster labels to original data and summarize\n",
    "\n",
    "df_clusters = df.copy()\n",
    "df_clusters[\"cluster\"] = best_labels\n",
    "\n",
    "cluster_summary = df_clusters.groupby(\"cluster\").mean(numeric_only=True)\n",
    "cluster_summary"
   ]
  },
 {
  "cell_type": "markdown",
  "id": "362fd77c",
  "metadata": {},
  "source": [
    "## 7. Summary of Results / ملخّص النتائج\n",
    "\n",
    "This section summarizes the main outputs obtained from the analysis:\n",
    "\n",
    "- `results_clf_df`: جدول يوضّح دقة نماذج شجرة القرار مع اختلاف معيار التقسيم ونسب تقسيم البيانات إلى تدريب/اختبار.  \n",
    "- Confusion matrices: توضح أداء النموذج في التمييز بين العينات الصالحة للشرب (1) وغير الصالحة (0).  \n",
    "- Best Decision Tree plot: يوضّح أهم المتغيرات المؤثرة في التنبؤ بصلاحية الماء وبعض قواعد التصنيف المستخلصة من الشجرة.  \n",
    "- `kmeans_results_df`: جدول يحتوي قيم الـ inertia والـ silhouette لمجموعة من قيم K في خوارزمية K-means.  \n",
    "- Elbow & Silhouette plots: تساعد في اختيار قيمة K الأنسب بناءً على شكل المنحنيات.  \n",
    "- `cluster_summary` مع مخطط الـ PCA: يبيّن خصائص كل Cluster من حيث متوسط قيم المتغيرات وربطها بجودة الماء.\n",
    "\n",
    "> يمكن الاعتماد على هذه النتائج في مناقشة أداء النماذج وربطها بالنتائج المذكورة في الورقة البحثية في تقرير المشروع النهائي.\n"
  ]
}
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
